version: '3'


services:

# Spark containers
  master:
    image: "spark-master:${APACHE_SPARK_VERSION}"

    networks:
      default:
        aliases:
          - spark_master
    
    ports:
      - "8080:8080"  # Spark master web UI

    volumes:
      - "${DATA_DIR:-/tmp}:/spark/data"

    user: root

    # command to start spark server
    command: /spark/start-spark-master.sh

  worker1:
    image: "spark-worker:${APACHE_SPARK_VERSION}"

    networks:
      default:
        aliases:
          - spark_worker1

    ports:
      - "18081:18081"

    volumes:
      - "${DATA_DIR:-/tmp}:/spark/data"

    user: root

    # command to start spark server
    command: /spark/start-spark-worker.sh  --cores 4 --memory 4g --webui-port 18081

  worker2:
    image: "spark-worker:${APACHE_SPARK_VERSION}"

    networks:
      default:
        aliases:
          - spark_worker2

    ports:
      - "28081:28081"

    volumes:
      - "${DATA_DIR:-/tmp}:/spark/data"

    user: root

    # command to start spark server
    command: /spark/start-spark-worker.sh  --cores 4 --memory 4g  --webui-port 28081

  pyspnb:
    image: "spark-pyspnb:${APACHE_SPARK_VERSION}"

    networks:
      default:
        aliases:
          - spark_client

    ports:
      - "8888:8888"  # jupyter notebook server
      - "4040-4042:4040-4042"  # spark job web ui

    volumes:
      - "${CODE_DIR:-/tmp}:/opt/project"
      - "${DATA_DIR:-/tmp}:/spark/data"

    user: root

    # command jupyter notebook server
    command: /spark/start-pyspnb.sh

#
#    tty: true
#    stdin_open: true